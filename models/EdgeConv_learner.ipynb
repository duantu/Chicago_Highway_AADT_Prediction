{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab2c09a-f767-48d5-8b87-530bee1a471e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../data/\"\n",
    "datafilename = \"Certainty.xlsx\"\n",
    "datafilepath = datadir + datafilename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ee5109-ca97-4027-8ab8-c624d73ff035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read in network information from sheet P0\n",
    "# For now we only use the folloiwng columns in each sheet\n",
    "cols_used = ['Link ID','ANODE','BNODE','A X_COORD','A Y_COORD','B X_COORD','B Y_COORD','Link Length(miles)','# of lanes-A','Capacity-A (veh/h)',\n",
    "            'auto volume(2010)-A','AADT(2010)-A','Speed(mph)-A','VMT-A']\n",
    "df_p0= pd.read_excel(datafilepath, sheet_name='P0',usecols=cols_used).dropna(subset=['Link ID'])\n",
    "\n",
    "# # For now we assume all occurrences of the same link in the same sheet share the same attribute values\n",
    "# df_p0_unique = df_p0.drop_duplicates(subset=['Link ID']).dropna(subset=['Link ID', 'A X_COORD', 'A Y_COORD', 'B X_COORD', 'B Y_COORD'])\n",
    "\n",
    "\n",
    "## Create a list of sheet names ##\n",
    "\n",
    "# List of the first 6 integers\n",
    "integers = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Function to generate combinations\n",
    "def generate_combinations(integers):\n",
    "    all_combinations = []\n",
    "    # Loop through lengths from 1 to 6\n",
    "    for length in range(1, 7):\n",
    "        # Generate combinations of the current length\n",
    "        comb = combinations(integers, length)\n",
    "        # Convert each combination to a string, add \"p\", and add to the list\n",
    "        all_combinations.extend(['P' + ''.join(map(str, c)) for c in comb])\n",
    "    return all_combinations\n",
    "\n",
    "# Generate all combinations\n",
    "sheet_names = generate_combinations(integers)\n",
    "\n",
    "# Insert \"P0\" at the beginning of the list\n",
    "sheet_names.insert(0, \"P0\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8778db-00c0-46fd-a2db-91fa88d8905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import EdgeConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "class EdgeLabelGNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EdgeLabelGNN, self).__init__()\n",
    "        self.conv1 = EdgeConv(nn=torch.nn.Sequential(\n",
    "            torch.nn.Linear(2 * 16, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, 16)\n",
    "        ))\n",
    "        self.fc = torch.nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######### Nodes ##############\n",
    "# colums that contain info about nodes in the graph\n",
    "node_info_cols = ['ANODE','BNODE','A X_COORD','A Y_COORD','B X_COORD','B Y_COORD']\n",
    "df_nodes= pd.read_excel(datafilepath, sheet_name='P0',usecols=node_info_cols).dropna(subset=['ANODE'])\n",
    "# unique nodes among ANODE\n",
    "df_nodes_ANODE_unique = df_nodes.drop_duplicates(subset=['ANODE'])\n",
    "# unique nodes among BNODE\n",
    "df_nodes_BNODE_unique = df_nodes.drop_duplicates(subset=['BNODE'])\n",
    "\n",
    "# index of unique nodes in ANODE\n",
    "ANODE_ind = df_nodes_ANODE_unique.index\n",
    "# X-coord and Y-coord of nodes listed as ANODES \n",
    "Anodes = np.array(df_p0.iloc[ANODE_ind-1].loc[:,['ANODE','A X_COORD','A Y_COORD']]).astype(float)\n",
    "\n",
    "# index of unique nodes in BNODE\n",
    "BNODE_ind = df_nodes_BNODE_unique.index\n",
    "# X-coord and Y-coord of nodes listed as BNODES \n",
    "Bnodes = np.array(df_p0.iloc[BNODE_ind-1].loc[:,['BNODE','B X_COORD','B Y_COORD']]).astype(float)\n",
    "\n",
    "# combine Anodes and Bnodes\n",
    "nodes = np.concatenate((Anodes, Bnodes))\n",
    "# combine the two index arrays into one, without repetition\n",
    "nodes_pd = pd.DataFrame(nodes)\n",
    "nodes_unique = nodes_pd.drop_duplicates(subset=[0])\n",
    "# Reset the index\n",
    "nodes_unique.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# convert nodes_unique to np array\n",
    "nodes_unique_arr = np.array(nodes_unique)\n",
    "x =  torch.from_numpy(nodes_unique_arr).to(dtype=torch.float)\n",
    "\n",
    "\n",
    "######### Edge Index #########\n",
    "edge_pairs = np.column_stack((df_p0['ANODE'],df_p0['BNODE']))\n",
    "edge_index = []\n",
    "for ii in range(len(edge_pairs)):\n",
    "    edge_node_ind = [nodes_unique[nodes_unique[0] == edge_pairs[ii,0]].index[0], nodes_unique[nodes_unique[0] == edge_pairs[ii,1]].index[0]]\n",
    "    # edge_index[:,ii]= edge_node_ind\n",
    "    edge_index.append(edge_node_ind)\n",
    "edge_index = torch.tensor(edge_index).t().contiguous() \n",
    "\n",
    "\n",
    "\n",
    "# Prepare the dataset \n",
    "data = []\n",
    "for ii in range(len(sheet_names)):\n",
    "    # read the correct sheet \n",
    "    df= pd.read_excel(datafilepath, sheet_name=sheet_names[ii],usecols=cols_used).dropna(subset=['Link ID'])\n",
    "    \n",
    "    # dataframe for edge attributes\n",
    "    df_edge_attr= np.column_stack((df['# of lanes-A'],df['Capacity-A (veh/h)'], df['Speed(mph)-A'],df['auto volume(2010)-A']))\n",
    "    edge_attr = torch.tensor(df_edge_attr, dtype=torch.float)\n",
    "    \n",
    "    labels = torch.tensor(df['AADT(2010)-A'].to_numpy(),dtype=torch.float)\n",
    "    new_data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=labels)\n",
    "    data.append(new_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02af35d2-b31a-4226-bbcc-ea6c3685fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define EdgeConv layer and network for predicting edge labels\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Define the EdgeConv layer with input and output dimensions\n",
    "        self.conv1 = EdgeConv(nn=torch.nn.Sequential(\n",
    "            torch.nn.Linear(2 * 3, 64),  # 3 features per node, concatenated for 6 features\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 32),\n",
    "            torch.nn.ReLU()\n",
    "        ))\n",
    "        self.conv2 = EdgeConv(nn=torch.nn.Sequential(\n",
    "            torch.nn.Linear(2 * 32, 64),  # 32 features per node from previous layer\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 32),\n",
    "            torch.nn.ReLU()\n",
    "        ))\n",
    "        \n",
    "        # Final layer for edge label prediction\n",
    "        self.edge_predictor = torch.nn.Sequential(\n",
    "            torch.nn.Linear(32 +32+ 4, 64),  # Concatenate node features with edge attributes\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 1)  # Output one label per edge\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        \n",
    "        # Apply EdgeConv layers\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        # Gather edge features by concatenating node features and edge attributes\n",
    "        row, col = edge_index\n",
    "        edge_features = torch.cat([x[row], x[col], edge_attr], dim=1)\n",
    "        \n",
    "        # Predict edge labels\n",
    "        edge_labels = self.edge_predictor(edge_features).squeeze()\n",
    "        \n",
    "        return edge_labels\n",
    "\n",
    "# Create DataLoader\n",
    "loader = DataLoader([data], batch_size=1)\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "model = Net()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1000):\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x, edge_index, edge_attr)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch}, Absolute Loss: {format(loss.item(),\".2e\")} ')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc851c7b-ea14-4348-a25a-4f3b37a1ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_tensor = criterion(torch.zeros(torch.Tensor.size(labels)), labels)\n",
    "loss_relative = loss/labels_tensor\n",
    "\n",
    "print(\"\\n Relative Loss = \", format(loss.item(), '.2e'), \" / \", format(labels_tensor.item(),'.2e'), \" = \", format(loss_relative.item(),'.2e'), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eddb2b5-28fc-462a-9b5c-ceff04a442ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Predicted AADT(after) = \", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9becf91-1feb-45f7-8356-c9b7b62b3b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test out preparing for data\n",
    "# import torch\n",
    "# from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "# # colums that contain info about nodes in the graph\n",
    "# node_info_cols = ['ANODE','BNODE','A X_COORD','A Y_COORD','B X_COORD','B Y_COORD']\n",
    "# df_nodes= pd.read_excel(datafilepath, sheet_name='P0',usecols=node_info_cols).dropna(subset=['ANODE'])\n",
    "# # unique nodes among ANODE\n",
    "# df_nodes_ANODE_unique = df_nodes.drop_duplicates(subset=['ANODE'])\n",
    "# # unique nodes among BNODE\n",
    "# df_nodes_BNODE_unique = df_nodes.drop_duplicates(subset=['BNODE'])\n",
    "# # index of unique nodes in ANODE\n",
    "# ANODE_ind = df_nodes_ANODE_unique.index\n",
    "# # index of unique nodes in BNODE\n",
    "# BNODE_ind = df_nodes_BNODE_unique.index\n",
    "# # combine the two index arrays into one, without repetition\n",
    "# nodes_ind=np.unique(np.concatenate((ANODE_ind, BNODE_ind)))\n",
    "\n",
    "\n",
    "# ### select rows included in nodes_ind and all the columns to be included in nodes.\n",
    "# nodes = np.array(df_p0.iloc[nodes_ind-1].loc[:,node_info_cols]).astype(float)\n",
    "# x =  torch.from_numpy(nodes)\n",
    "\n",
    "# ###########\n",
    "\n",
    "\n",
    "# # edge index (ANODE)\n",
    "# edge_index = torch.tensor([df_p0['ANODE'].to_numpy(),df_p0['BNODE'].to_numpy()], dtype=torch.long).t().contiguous()\n",
    "\n",
    "\n",
    "# # Prepare the dataset \n",
    "# dataset = []\n",
    "# for ii in range(len(sheet_names)):\n",
    "#     # read the correct sheet \n",
    "#     df= pd.read_excel(datafilepath, sheet_name=sheet_names[ii],usecols=cols_used).dropna(subset=['Link ID'])\n",
    "\n",
    "#     edge_attr = torch.tensor([df['# of lanes-A'].to_numpy(), df['Capacity-A (veh/h)'].to_numpy()], dtype=torch.float)\n",
    "#     labels = torch.tensor([df['auto volume(2010)-A'].to_numpy()],dtype=torch.float)\n",
    "#     data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=labels)\n",
    "#     dataset.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2f9956-8d20-4fc5-be8d-e21c4be45baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch_geometric.data import Data\n",
    "\n",
    "# ######### Nodes ##############\n",
    "# # colums that contain info about nodes in the graph\n",
    "# node_info_cols = ['ANODE','BNODE','A X_COORD','A Y_COORD','B X_COORD','B Y_COORD']\n",
    "# df_nodes= pd.read_excel(datafilepath, sheet_name='P0',usecols=node_info_cols).dropna(subset=['ANODE'])\n",
    "# # unique nodes among ANODE\n",
    "# df_nodes_ANODE_unique = df_nodes.drop_duplicates(subset=['ANODE'])\n",
    "# # unique nodes among BNODE\n",
    "# df_nodes_BNODE_unique = df_nodes.drop_duplicates(subset=['BNODE'])\n",
    "\n",
    "# # index of unique nodes in ANODE\n",
    "# ANODE_ind = df_nodes_ANODE_unique.index\n",
    "# # X-coord and Y-coord of nodes listed as ANODES \n",
    "# Anodes = np.array(df_p0.iloc[ANODE_ind-1].loc[:,['ANODE','A X_COORD','A Y_COORD']]).astype(float)\n",
    "\n",
    "# # index of unique nodes in BNODE\n",
    "# BNODE_ind = df_nodes_BNODE_unique.index\n",
    "# # X-coord and Y-coord of nodes listed as BNODES \n",
    "# Bnodes = np.array(df_p0.iloc[BNODE_ind-1].loc[:,['BNODE','B X_COORD','B Y_COORD']]).astype(float)\n",
    "\n",
    "# # combine Anodes and Bnodes\n",
    "# nodes = np.concatenate((Anodes, Bnodes))\n",
    "# # combine the two index arrays into one, without repetition\n",
    "# nodes_pd = pd.DataFrame(nodes)\n",
    "# nodes_unique = nodes_pd.drop_duplicates(subset=[0])\n",
    "\n",
    "# # convert nodes_unique to np array\n",
    "# nodes_unique_arr = np.array(nodes_unique)\n",
    "# x =  torch.from_numpy(nodes_unique_arr)\n",
    "\n",
    "\n",
    "# ######### Edge Index #########\n",
    "# edge_pairs = np.column_stack((df_p0['ANODE'],df_p0['BNODE']))\n",
    "# edge_index = []\n",
    "# for ii in range(len(edge_pairs)):\n",
    "#     edge_node_ind = [nodes_unique[nodes_unique[0] == edge_pairs[ii,0]].index[0], nodes_unique[nodes_unique[0] == edge_pairs[ii,1]].index[0]]\n",
    "#     # edge_index[:,ii]= edge_node_ind\n",
    "#     edge_index.append(edge_node_ind)\n",
    "# edge_index = torch.tensor(edge_index).t().contiguous() \n",
    "\n",
    "# ######## Edge Attributes ########\n",
    "\n",
    "# ######## Edge Label #########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039cb408-dbb1-48cb-a58c-e30ebd5c704c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66fe6a3-8ae4-4884-af51-9239b194c9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0d5942-28bf-4780-a3e7-720fdc6efabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EdgeLabelGNN(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(EdgeLabelGNN, self).__init__()\n",
    "#         self.conv1 = EdgeConv(nn=torch.nn.Sequential(\n",
    "#             torch.nn.Linear(2 * 3, 64),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.Linear(64, 32)\n",
    "#         ))\n",
    "#         self.fc = torch.nn.Linear(16, 1)\n",
    "\n",
    "#     def forward(self, x, edge_index, edge_attr):\n",
    "#         x = self.conv1(x, edge_index)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.fc(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "\n",
    "# # Training loop\n",
    "# for epoch in range(100):\n",
    "#     for batch in loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         # out = model(x,edge_index, edge_attr)\n",
    "#         # loss = criterion(out, y)\n",
    "#         out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "#         loss = criterion(out, batch.y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942bfa1f-9b0d-49e4-9c1e-e88c3d5ab81d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732cd391-0b07-49b0-aa36-f59d599536a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2598896f-50b7-4280-bf4b-94fee77b0782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c804d1d-4e74-4655-b6e0-5720f7c7c485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6911177-d049-4adf-bac3-6e733c172a50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80e286a-57d0-4ea0-9908-41b98ecfb78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning with EdgeConv, suggested by ChatGPT\n",
    "\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch_geometric.nn import EdgeConv\n",
    "# from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "# class EdgeLabelGNN(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(EdgeLabelGNN, self).__init__()\n",
    "#         self.conv1 = EdgeConv(nn=torch.nn.Sequential(\n",
    "#             torch.nn.Linear(2 * 16, 32),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.Linear(32, 16)\n",
    "#         ))\n",
    "#         self.fc = torch.nn.Linear(16, 1)\n",
    "\n",
    "#     def forward(self, x, edge_index, edge_attr):\n",
    "#         x = self.conv1(x, edge_index)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.fc(x)\n",
    "#         return x\n",
    "\n",
    "# # Example Data Preparation\n",
    "# edge_index = torch.tensor([[0, 1], [1, 2]], dtype=torch.long).t().contiguous()\n",
    "# edge_attr = torch.tensor([[3, 5], [2, 4]], dtype=torch.float)\n",
    "# y = torch.tensor([1.0, 0.5], dtype=torch.float)\n",
    "\n",
    "# data = Data(edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "\n",
    "# # Create DataLoader\n",
    "# loader = DataLoader([data], batch_size=1)\n",
    "\n",
    "# # Initialize model, optimizer, and loss function\n",
    "# model = EdgeLabelGNN()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# criterion = torch.nn.MSELoss()\n",
    "\n",
    "# # Training loop\n",
    "# for epoch in range(100):\n",
    "#     for batch in loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "#         loss = criterion(out, batch.y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebbfc44-12b6-42ac-bca3-b3074c97f4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeba1fa0-7a75-4cc5-86e5-73b525a25b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
