{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5acddeba-4c8e-4ac8-9536-03b5bf100c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../data/\"\n",
    "datafilename = \"Certainty.xlsx\"\n",
    "datafilepath = datadir + datafilename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98cab0cb-1dd6-4ff3-b019-35fd66995d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read in network information from sheet P0\n",
    "# For now we only use the folloiwng columns in each sheet\n",
    "cols_used = ['Link ID','ANODE','BNODE','A X_COORD','A Y_COORD','B X_COORD','B Y_COORD','Link Length(miles)','# of lanes-A','Capacity-A (veh/h)',\n",
    "            'auto volume(2010)-A','AADT(2010)-A','Speed(mph)-A','VMT-A']\n",
    "df_p0= pd.read_excel(datafilepath, sheet_name='P0',usecols=cols_used).dropna(subset=['Link ID'])\n",
    "\n",
    "# # For now we assume all occurrences of the same link in the same sheet share the same attribute values\n",
    "# df_p0_unique = df_p0.drop_duplicates(subset=['Link ID']).dropna(subset=['Link ID', 'A X_COORD', 'A Y_COORD', 'B X_COORD', 'B Y_COORD'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "986e3f0f-2b51-4412-8b4e-e043a78f16d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Only Read in Project 3, 4 and 5\n",
    "integers = [ 3, 4, 5]\n",
    "def generate_combinations(integers):\n",
    "    all_combinations = []\n",
    "    # Loop through lengths from 1 to 6\n",
    "    for length in range(1, 1+len(integers)):\n",
    "        # Generate combinations of the current length\n",
    "        comb = combinations(integers, length)\n",
    "        # Convert each combination to a string, add \"p\", and add to the list\n",
    "        all_combinations.extend(['P' + ''.join(map(str, c)) for c in comb])\n",
    "    return all_combinations\n",
    "# Generate all combinations\n",
    "sheet_names = generate_combinations(integers)\n",
    "\n",
    "# Insert \"P0\" at the beginning of the list\n",
    "sheet_names.insert(0, \"P0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15ac74a1-b071-4197-aa23-414142af76f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Read in all 2^6 sheets of data ###\n",
    "\n",
    "\n",
    "# ## Create a list of sheet names ##\n",
    "\n",
    "# # List of the first 6 integers\n",
    "# integers = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# # Function to generate combinations\n",
    "# def generate_combinations(integers):\n",
    "#     all_combinations = []\n",
    "#     # Loop through lengths from 1 to 6\n",
    "#     for length in range(1, 7):\n",
    "#         # Generate combinations of the current length\n",
    "#         comb = combinations(integers, length)\n",
    "#         # Convert each combination to a string, add \"p\", and add to the list\n",
    "#         all_combinations.extend(['P' + ''.join(map(str, c)) for c in comb])\n",
    "#     return all_combinations\n",
    "\n",
    "# # Generate all combinations\n",
    "# sheet_names = generate_combinations(integers)\n",
    "\n",
    "# # Insert \"P0\" at the beginning of the list\n",
    "# sheet_names.insert(0, \"P0\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ddc5c80-0f38-4282-8326-88979fa4e458",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duantu/soft/transportation_venv/lib/python3.12/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F \n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import TransformerConv\n",
    "import random\n",
    "\n",
    "\n",
    "### Data Preparation ###\n",
    "\n",
    "######### Nodes ##############\n",
    "# colums that contain info about nodes in the graph\n",
    "node_info_cols = ['ANODE','BNODE','A X_COORD','A Y_COORD','B X_COORD','B Y_COORD']\n",
    "df_nodes= pd.read_excel(datafilepath, sheet_name='P0',usecols=node_info_cols).dropna(subset=['ANODE'])\n",
    "# unique nodes among ANODE\n",
    "df_nodes_ANODE_unique = df_nodes.drop_duplicates(subset=['ANODE'])\n",
    "# unique nodes among BNODE\n",
    "df_nodes_BNODE_unique = df_nodes.drop_duplicates(subset=['BNODE'])\n",
    "\n",
    "# index of unique nodes in ANODE\n",
    "ANODE_ind = df_nodes_ANODE_unique.index\n",
    "# X-coord and Y-coord of nodes listed as ANODES \n",
    "Anodes = np.array(df_p0.iloc[ANODE_ind-1].loc[:,['ANODE','A X_COORD','A Y_COORD']]).astype(float)\n",
    "\n",
    "# index of unique nodes in BNODE\n",
    "BNODE_ind = df_nodes_BNODE_unique.index\n",
    "# X-coord and Y-coord of nodes listed as BNODES \n",
    "Bnodes = np.array(df_p0.iloc[BNODE_ind-1].loc[:,['BNODE','B X_COORD','B Y_COORD']]).astype(float)\n",
    "\n",
    "# combine Anodes and Bnodes\n",
    "nodes = np.concatenate((Anodes, Bnodes))\n",
    "# combine the two index arrays into one, without repetition\n",
    "nodes_pd = pd.DataFrame(nodes)\n",
    "nodes_unique = nodes_pd.drop_duplicates(subset=[0])\n",
    "# Reset the index\n",
    "nodes_unique.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# convert nodes_unique to np array\n",
    "nodes_unique_arr = np.array(nodes_unique)\n",
    "x =  torch.from_numpy(nodes_unique_arr).to(dtype=torch.float)\n",
    "\n",
    "\n",
    "######### Edge Index #########\n",
    "edge_pairs = np.column_stack((df_p0['ANODE'],df_p0['BNODE']))\n",
    "edge_index = []\n",
    "for ii in range(len(edge_pairs)):\n",
    "    edge_node_ind = [nodes_unique[nodes_unique[0] == edge_pairs[ii,0]].index[0], nodes_unique[nodes_unique[0] == edge_pairs[ii,1]].index[0]]\n",
    "    # edge_index[:,ii]= edge_node_ind\n",
    "    edge_index.append(edge_node_ind)\n",
    "edge_index = torch.tensor(edge_index).t().contiguous() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e652e6a-07f3-4788-b1e0-a099bda82062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data to be in the range (0,1) with minmaxsclaer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fcbbad-6754-4c89-b5ec-9eb81148cc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset \n",
    "dataset = []\n",
    "for ii in range(len(sheet_names)):\n",
    "    # read the correct sheet \n",
    "    df= pd.read_excel(datafilepath, sheet_name=sheet_names[ii],usecols=cols_used).dropna(subset=['Link ID'])\n",
    "    \n",
    "    # dataframe for edge attributes\n",
    "    df_edge_attr= np.column_stack((df['# of lanes-A'],df['Capacity-A (veh/h)'], df['Speed(mph)-A'],df['auto volume(2010)-A']))\n",
    "    edge_attr = torch.tensor(df_edge_attr, dtype=torch.float)\n",
    "    \n",
    "    edge_labels = torch.tensor(df['AADT(2010)-A'].to_numpy(),dtype=torch.float)\n",
    "    new_data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=edge_labels)\n",
    "    dataset.append(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b099948-b6aa-4cea-8b4f-09de9c773345",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EdgeLabelPredictor(torch.nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_dim):\n",
    "        super(EdgeLabelPredictor, self).__init__()\n",
    "        self.conv1 = TransformerConv(node_features, hidden_dim, edge_dim=edge_features)\n",
    "        self.conv2 = TransformerConv(hidden_dim, hidden_dim, edge_dim=edge_features)\n",
    "        # self.edge_fc = torch.nn.Linear(hidden_dim, 1)\n",
    "        self.edge_fc = torch.nn.Linear(2 * hidden_dim+edge_features, 1)\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # import pdb;pdb.set_trace()\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.relu(self.conv2(x, edge_index, edge_attr))\n",
    "        edge_features = torch.cat([x[edge_index[0]], x[edge_index[1]], edge_attr],dim=1)\n",
    "        edge_features = self.edge_fc(edge_features)\n",
    "        return F.relu(edge_features)  # Ensure the output is positive\n",
    "\n",
    "# Example data\n",
    "node_features = 3\n",
    "edge_features = 4\n",
    "hidden_dim = 16\n",
    "\n",
    "model = EdgeLabelPredictor(node_features, edge_features, hidden_dim)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5b7870b-eabe-4dbf-80b3-3638c87fac17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_37611/3971059052.py\u001b[0m(11)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      9 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     10 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 11 \u001b[0;31m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     12 \u001b[0;31m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     13 \u001b[0;31m        \u001b[0medge_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   8921.0000,  407624.1875, 4649654.5000],\n",
      "        [   9137.0000,  409288.5938, 4649934.5000],\n",
      "        [   9027.0000,  408444.0000, 4649861.0000],\n",
      "        ...,\n",
      "        [   5142.0000,  343164.3125, 4677479.0000],\n",
      "        [   5114.0000,  338274.5000, 4679260.0000],\n",
      "        [   8694.0000,  405621.8125, 4648465.5000]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  x.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([642, 3])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  edge_attr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000e+00, 4.0000e+03, 5.4972e+01, 1.5688e+04],\n",
      "        [2.0000e+00, 4.0000e+03, 5.4626e+01, 2.5747e+04],\n",
      "        [2.0000e+00, 4.0000e+03, 5.4384e+01, 2.8633e+04],\n",
      "        ...,\n",
      "        [2.0000e+00, 1.4500e+03, 2.8669e+01, 1.2636e+04],\n",
      "        [1.0000e+00, 1.4500e+03, 2.7834e+01, 1.4399e+04],\n",
      "        [2.0000e+00, 1.4500e+03, 2.9577e+01, 9.1786e+03]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_37611/3971059052.py\u001b[0m(12)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     10 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     11 \u001b[0;31m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 12 \u001b[0;31m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     13 \u001b[0;31m        \u001b[0medge_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     14 \u001b[0;31m        \u001b[0medge_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  edge_attr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000e+00, 4.0000e+03, 5.4972e+01, 1.5688e+04],\n",
      "        [2.0000e+00, 4.0000e+03, 5.4626e+01, 2.5747e+04],\n",
      "        [2.0000e+00, 4.0000e+03, 5.4384e+01, 2.8633e+04],\n",
      "        ...,\n",
      "        [2.0000e+00, 1.4500e+03, 2.8669e+01, 1.2636e+04],\n",
      "        [1.0000e+00, 1.4500e+03, 2.7834e+01, 1.4399e+04],\n",
      "        [2.0000e+00, 1.4500e+03, 2.9577e+01, 9.1786e+03]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 992488.3750,  944507.3750, 1228445.7500,  ...,       0.0000,\n",
      "               0.0000,       0.0000],\n",
      "        [ 987246.0000,  941804.5000, 1240256.1250,  ...,       0.0000,\n",
      "               0.0000,       0.0000],\n",
      "        [2328476.0000,       0.0000,  686294.5625,  ...,       0.0000,\n",
      "               0.0000,       0.0000],\n",
      "        ...,\n",
      "        [ 999123.1250,  956286.3750, 1234016.7500,  ...,       0.0000,\n",
      "               0.0000,       0.0000],\n",
      "        [1002547.0000,  953167.7500, 1230584.8750,  ...,       0.0000,\n",
      "               0.0000,       0.0000],\n",
      "        [ 990164.5000,  944348.5000, 1231490.7500,  ...,       0.0000,\n",
      "               0.0000,       0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  x.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([642, 16])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_37611/3971059052.py\u001b[0m(13)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     11 \u001b[0;31m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     12 \u001b[0;31m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 13 \u001b[0;31m        \u001b[0medge_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     14 \u001b[0;31m        \u001b[0medge_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     15 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_features\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure the output is positive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[      0.0000,       0.0000,  304202.8750,  ..., 1184145.8750,\n",
      "               0.0000, 1046790.8750],\n",
      "        [      0.0000,       0.0000,  299356.1250,  ..., 1192360.2500,\n",
      "               0.0000, 1050666.6250],\n",
      "        [      0.0000,  447058.2188,   61480.0195,  ...,  266198.1250,\n",
      "          828557.9375,   23093.1543],\n",
      "        ...,\n",
      "        [      0.0000,       0.0000,  314879.3750,  ..., 1194275.8750,\n",
      "               0.0000, 1066968.1250],\n",
      "        [      0.0000,  292806.6875,       0.0000,  ...,  999621.5000,\n",
      "               0.0000,  369418.6875],\n",
      "        [      0.0000,       0.0000,  301812.0625,  ..., 1188058.2500,\n",
      "               0.0000, 1047484.7500]], grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_37611/3971059052.py\u001b[0m(14)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     12 \u001b[0;31m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     13 \u001b[0;31m        \u001b[0medge_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 14 \u001b[0;31m        \u001b[0medge_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     15 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_features\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure the output is positive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_37611/3971059052.py\u001b[0m(15)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     13 \u001b[0;31m        \u001b[0medge_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     14 \u001b[0;31m        \u001b[0medge_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 15 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_features\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure the output is positive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m\u001b[0;31m# Example data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([[ 316...eluBackward0>)\n",
      "> \u001b[0;32m/tmp/ipykernel_37611/3971059052.py\u001b[0m(15)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     13 \u001b[0;31m        \u001b[0medge_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     14 \u001b[0;31m        \u001b[0medge_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 15 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_features\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure the output is positive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m\u001b[0;31m# Example data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "tensor([[ 316...eluBackward0>)\n",
      "> \u001b[0;32m/home/duantu/soft/transportation_venv/lib/python3.12/site-packages/torch/nn/modules/module.py\u001b[0m(1541)\u001b[0;36m_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1539 \u001b[0;31m                \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1540 \u001b[0;31m                \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_pre_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1541 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1542 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1543 \u001b[0;31m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# dataset = [data]\n",
    "# Create a data loader (replace with your actual dataset)\n",
    "loader = DataLoader(dataset, batch_size=1,shuffle=True)\n",
    "\n",
    "# Training settings\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(100):  # Adjust the number of epochs as needed\n",
    "    # ii=1\n",
    "    epoch_loss = 0.0\n",
    "    for batch in loader:\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index, batch.edge_attr).squeeze()\n",
    "        # print('batch #',ii, batch.edge_attr)\n",
    "        loss = criterion(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        # ii = ii+1\n",
    "        \n",
    "    # print(f'Epoch {epoch + 1}, Absolute Loss: {format(loss.item(),\".2e\")}')\n",
    "    print(f'Epoch {epoch + 1}, Absolute Loss: {format(epoch_loss/len(loader),\".2e\")}')\n",
    "############ DEBUGGING FOR ALL ZERO GRADIENTS #######\n",
    "# for epoch in range(10):  # Adjust the number of epochs as needed\n",
    "#     epoch_loss = 0.0\n",
    "#     for ii, batch in enumerate(loader, start=1):\n",
    "#                 optimizer.zero_grad()\n",
    "#                 out = model(batch.x, batch.edge_index, batch.edge_attr).squeeze()\n",
    "    \n",
    "#                 loss = criterion(out, batch.y)\n",
    "#                 loss.backward()\n",
    "                \n",
    "#                 # Print gradients for debugging\n",
    "#                 for name, param in model.named_parameters():\n",
    "#                     if param.grad is not None:\n",
    "#                         print(f\"Gradients for {name}: {param.grad.norm().item():.2e}\")\n",
    "#                     else:\n",
    "#                         print(f\"No gradients for {name}\")\n",
    "#                 # for name, param in model.named_parameters():\n",
    "                #     if param.requires_grad:\n",
    "                #         print(f\"{name}: {param.data[:5]}\")      \n",
    "    #             optimizer.step()\n",
    "    \n",
    "    #             epoch_loss += loss.item()\n",
    "    #             print(f'Batch #{ii}, Batch Edge Attr: {batch.edge_attr}')\n",
    "        \n",
    "    # print(f'Epoch {epoch + 1}, Absolute Loss: {format(epoch_loss, \".2e\")}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Model evaluation \n",
    "model.eval()\n",
    "\n",
    "#     ### Model eval on 1 randomly selected sample ###\n",
    "# with torch.no_grad():\n",
    "#     # randomly shuffle the set of 8 samples and then use the first sample for model eval\n",
    "#     random.shuffle(dataset)\n",
    "#     edge_attr_eval = dataset[0].edge_attr \n",
    "#     out = model(x, edge_index, edge_attr_eval).squeeze()\n",
    "#     mse = criterion(out, edge_labels.squeeze()).item()\n",
    "#     print(f'Mean Squared Error on a randomly selected sample: {format(mse, \".2e\")}')\n",
    "\n",
    "    ### Model eval on the entire dataset of 8 samples ###\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "    \n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        out = model(batch.x, batch.edge_index, batch.edge_attr).squeeze()\n",
    "        all_preds.append(out)\n",
    "        all_labels.append(batch.y)  \n",
    "\n",
    "# Concatenate all predictions and labels\n",
    "all_preds = torch.cat(all_preds, dim=0)\n",
    "all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "mse = criterion(all_preds, all_labels.squeeze()).item()\n",
    "print(f'Mean Squared Error on the entire dataset: {format(mse, \".2e\")}')\n",
    "\n",
    "    \n",
    "\n",
    "# Calculate Relative Error\n",
    "edge_labels_tensor = criterion(torch.zeros(torch.Tensor.size(edge_labels)), edge_labels)\n",
    "loss_relative = mse/edge_labels_tensor\n",
    "\n",
    "print(\"\\n Relative Loss = \", format(mse, '.2e'), \" / \", format(edge_labels_tensor.item(),'.2e'), \" = \", format(loss_relative.item(),'.2e'), \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c688333-6b38-482e-9b18-61484fcbceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('The predicted AADT for P0: \\n', all_preds[:650])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067ebca3-ac2a-4f36-960b-8951449a587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
